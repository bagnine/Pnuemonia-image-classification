{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as pd\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.image import rgb_to_grayscale\n",
    "\n",
    "\n",
    "# Reshaping \n",
    "from tensorflow import reshape\n",
    "from tensorflow.image import resize_with_pad\n",
    "\n",
    "\n",
    "# Modelling \n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# metrics\n",
    "from tensorflow.keras.metrics import Recall, AUC\n",
    "\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train Data From the Current Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get current working directory\n",
    "# PATH = os.getcwd() + '/../../src/data/chest_xray/'\n",
    "\n",
    "\n",
    "# # importing training normal data\n",
    "# norm_train_path = PATH+'train/NORMAL/'\n",
    "# norm_train_batch = os.listdir(norm_train_path) \n",
    "\n",
    "# norm_train = []\n",
    "# norm_errors = []\n",
    "# for image_name in (norm_train_batch[:10]): \n",
    "#     img_path = norm_train_path + image_name \n",
    "#     try:\n",
    "#         x = image.load_img(img_path) \n",
    "#         # preprocessing if required \n",
    "#         norm_train.append(x) \n",
    "#     except:\n",
    "#         norm_errors.append(image_name)\n",
    "    \n",
    "    \n",
    "# # importing training pnuemonia data\n",
    "# pnue_train_path = PATH + 'train/PNEUMONIA/'\n",
    "# pnue_train_batch = os.listdir(pnue_train_path)\n",
    "\n",
    "# pnue_train = []\n",
    "# pnue_errors = []\n",
    "# for image_name in pnue_train_batch[:10]:\n",
    "#     img_path = pnue_train_path + image_name\n",
    "#     try:\n",
    "#         x = image.load_img(img_path)\n",
    "#         pnue_train.append(x)\n",
    "#     except:\n",
    "#         pnue_errors.append(image_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define an import function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_image(PATH, image_name):\n",
    "    \"\"\"\n",
    "    PATH --> str: Relative path to image directoy\n",
    "    image_name --> str: Name of the image to load\n",
    "    \n",
    "    Returns:\n",
    "    PIL image\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # create path to file\n",
    "    img_path = PATH + \"/\" + image_name\n",
    "    \n",
    "    # load file and return pil\n",
    "    return image.load_img(img_path) \n",
    "\n",
    "def grayscale_and_resize(PIL, shape=(256,256), padding=False, grayscale=True):\n",
    "    \"\"\"\n",
    "    This is the preprocessing function that will take the raw jpeg, gray scale it, resize it and \n",
    "    turn it into an array\n",
    "    \n",
    "    \n",
    "    PIL --> PIL object\n",
    "    shape --> tuple: size of the final array\n",
    "    padding --> bool: if True, will use tf.resize_with_pad\n",
    "    \"\"\"\n",
    "    if padding:\n",
    "        gray_image = rgb_to_grayscale(PIL)\n",
    "        resized_image_arr = resize_with_pad(gray_image, target_height=shape[0], target_width=shape[1])\n",
    "    else:\n",
    "        if grayscale:\n",
    "            resized_image_arr = img_to_array(PIL.convert(mode = 'L').resize(shape))\n",
    "        else:\n",
    "            resized_image_arr = img_to_array(PIL.resize(shape))\n",
    "    \n",
    "    return resized_image_arr\n",
    "\n",
    "\n",
    "def import_image_to_array(\n",
    "         RELPATH,\n",
    "         dir_names = ['train', 'test', 'val'],\n",
    "         sub_dir_names = ['NORMAL', 'PNEUMONIA'],\n",
    "         padding=False,\n",
    "         shape=(256,256),\n",
    "         grayscale=True,\n",
    "         test=False\n",
    "):\n",
    "    \"\"\"\n",
    "    This function loads all train, test and validation data into a dictionary of images\n",
    "    \n",
    "    Padding currently only returns a grayscale image.\n",
    "    \n",
    "    =====================================================================================\n",
    "    RELPATH --> str: The relative path to the cwd to the directory containing image directories\n",
    "    eg '../../src/data/chest_xray'\n",
    "    =====================================================================================\n",
    "    dir_names --> list, str: The names of the subdirectories containing the images\n",
    "    eg ['train', 'test', 'val'] <-- default\n",
    "    =====================================================================================\n",
    "    sub_dir_names --> list -> str: names of the subdirectory containg postivie and negative cases\n",
    "    eg ['NORMAL', 'PNEUMONIA'] <-- default\n",
    "    =====================================================================================\n",
    "    padding  --> bool: Whether you want the reshaping to be padded or not\n",
    "    \n",
    "    =====================================================================================\n",
    "    shape --> tuple-> int: The final shape of the tensor array\n",
    "    =====================================================================================  \n",
    "    grayscale --> Bool: if True, images will be reduced to grayscale (x,x,1) else (x,x,3)\n",
    "    \n",
    "    returns\n",
    "    \n",
    "    dict --> str:list -> tuple -> (tf.array, bool)\n",
    "    A dictionary where the keys are the dir_names and the values are lists containing tuple where \n",
    "    the first index is the tf.array and the second is a boolian, True if class is pnuemonia, false otherwise.\n",
    "    \"\"\"\n",
    "    # test relative path works!! \n",
    "    PATH = os.getcwd() + RELPATH\n",
    "    \n",
    "    try:\n",
    "        os.listdir(PATH)\n",
    "        print(\"Your relative directory is good, proceeding to import files...\", end=\"\\n\\n\")\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        print(f\"Your relative path directory is not pointing to the correct location. Double check your input \\n\")\n",
    "        print(\"Terminating Program\", end='\\n')\n",
    "        print(\"=======================================================================================\")\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    # instantiate a dict object and populate the keys\n",
    "    image_dict = {}\n",
    "    for name in dir_names:\n",
    "        image_dict[name] = []\n",
    "        \n",
    "        print(f\"Loading images from {name}\", end='\\n')\n",
    "        \n",
    "        \n",
    "        # For each subdirectory, get all of the images and append to dictionary\n",
    "        for sub_dir in sub_dir_names:\n",
    "            subPATH = PATH + name + \"/\" + sub_dir\n",
    "            # list of all image names in the subdirectory\n",
    "            image_batch = os.listdir(subPATH)\n",
    "            \n",
    "            for image in image_batch:\n",
    "                # import the image in pil format\n",
    "                pil = import_image(subPATH, image)\n",
    "                # gray scale and reshape the image turning it into an array\n",
    "                gray_resized_pil = grayscale_and_resize(pil, shape=shape, padding=padding, grayscale=grayscale)\n",
    "                \n",
    "                # center the pixels\n",
    "                centered_array = gray_resized_pil/255\n",
    "                \n",
    "                # append to the image_dict with class flag\n",
    "                flag = 1\n",
    "                if sub_dir == 'NORMAL':\n",
    "                    flag = 0\n",
    "                \n",
    "                image_dict[name].append((image, centered_array, flag))\n",
    "                \n",
    "            \n",
    "                # if this is just a test case, break out of this loop so we get one from each class\n",
    "                if test == True:\n",
    "                    break\n",
    "            \n",
    "            print(f\"Finished loading images from {sub_dir}\", end=\"\\n\")\n",
    "\n",
    "        print()\n",
    "    \n",
    "    return image_dict               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your relative directory is good, proceeding to import files...\n",
      "\n",
      "Loading images from train\n",
      "Finished loading images from NORMAL\n",
      "Finished loading images from PNEUMONIA\n",
      "\n",
      "Loading images from test\n",
      "Finished loading images from NORMAL\n",
      "Finished loading images from PNEUMONIA\n",
      "\n",
      "Loading images from val\n",
      "Finished loading images from NORMAL\n",
      "Finished loading images from PNEUMONIA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images = import_image_to_array('/../../src/data/chest_xray/',test=False, grayscale=False, shape=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'person109_bacteria_526.jpeg'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images['test'][300][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>pnuemonia</th>\n",
       "      <th>bacterial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IM-0031-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IM-0025-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NORMAL2-IM-0272-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NORMAL2-IM-0102-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NORMAL2-IM-0229-0001.jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>person120_bacteria_572.jpeg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>person171_bacteria_826.jpeg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>person109_bacteria_512.jpeg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>person83_bacteria_410.jpeg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>person112_bacteria_538.jpeg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      image_name pnuemonia bacterial\n",
       "0              IM-0031-0001.jpeg         0         0\n",
       "1              IM-0025-0001.jpeg         0         0\n",
       "2      NORMAL2-IM-0272-0001.jpeg         0         0\n",
       "3      NORMAL2-IM-0102-0001.jpeg         0         0\n",
       "4      NORMAL2-IM-0229-0001.jpeg         0         0\n",
       "..                           ...       ...       ...\n",
       "619  person120_bacteria_572.jpeg         1         1\n",
       "620  person171_bacteria_826.jpeg         1         1\n",
       "621  person109_bacteria_512.jpeg         1         1\n",
       "622   person83_bacteria_410.jpeg         1         1\n",
       "623  person112_bacteria_538.jpeg         1         1\n",
       "\n",
       "[624 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_name = [i[0] for i in images['test']]\n",
    "test_image_class = [i[2] for i in images['test']]\n",
    "is_bacterial = [1 if i[0].find(\"bacteria\") != -1 else 0 for i in images['test']]\n",
    "test_df = pd.DataFrame([test_image_name, test_image_class, is_bacterial]).T\n",
    "test_df.columns = ['image_name', 'pnuemonia', \"bacterial\"]\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for class imbalance in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([i[1] for i in images['train']])\n",
    "X_train = np.array([i[0] for i in images['train']])  \n",
    "\n",
    "\n",
    "X_test = np.array([i[0] for i in images['test']])\n",
    "y_test = np.array([i[1] for i in images['test']])\n",
    "\n",
    "\n",
    "X_val = np.array([i[0] for i in images['val']])\n",
    "y_val = np.array([i[1] for i in images['val']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate inverse frequency of each class \n",
    "pnue_frequency = sum(y_train)/len(y_train)\n",
    "inv_pnue_frequency = 1/pnue_frequency\n",
    "\n",
    "normal_frequency = (len(y_train)-sum(y_train))/len(y_train)\n",
    "inv_normal_frequency = 1/normal_frequency\n",
    "\n",
    "# save weights as a dictionary to be used in the model\n",
    "weights = {\n",
    "    0: inv_normal_frequency,\n",
    "    1: inv_pnue_frequency\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential()\n",
    "adam = Adam()\n",
    "recall = Recall()\n",
    "AUC = AUC()\n",
    "# Input layer conv\n",
    "cnn.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256,  1)))\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# First hidden layer conv\n",
    "cnn.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn.add(layers.Dropout(0.2))\n",
    "cnn.add(layers.Flatten())\n",
    "\n",
    "# Added first/MASSIVE dense layer\n",
    "cnn.add(layers.Dense(1024, activation='relu'))\n",
    "cnn.add(layers.Dropout(.5))\n",
    "\n",
    "# Add Second Layer dense \n",
    "cnn.add(layers.Dense(32, activation='relu'))\n",
    "cnn.add(layers.Dropout(.1))\n",
    "\n",
    "# Add third Layer dense\n",
    "cnn.add(layers.Dense(16, activation='relu'))\n",
    "cnn.add(layers.Dropout(.1))\n",
    "\n",
    "# Added output layer \n",
    "cnn.add(layers.Dense(1, activation='sigmoid'))\n",
    "cnn.compile(loss='binary_crossentropy',\n",
    "              optimizer= adam,\n",
    "              metrics=['acc', recall, AUC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "105/105 [==============================] - 838s 8s/step - loss: 0.9353 - acc: 0.8183 - recall_4: 0.8477 - auc_2: 0.8864 - val_loss: 0.2041 - val_acc: 0.9375 - val_recall_4: 1.0000 - val_auc_2: 0.9844\n",
      "Epoch 2/10\n",
      "105/105 [==============================] - 679s 6s/step - loss: 0.3805 - acc: 0.9273 - recall_4: 0.9239 - auc_2: 0.9764 - val_loss: 0.2901 - val_acc: 0.9375 - val_recall_4: 1.0000 - val_auc_2: 1.0000\n",
      "Epoch 3/10\n",
      "105/105 [==============================] - 704s 7s/step - loss: 0.2863 - acc: 0.9490 - recall_4: 0.9463 - auc_2: 0.9860 - val_loss: 0.1445 - val_acc: 0.9375 - val_recall_4: 1.0000 - val_auc_2: 1.0000\n",
      "Epoch 4/10\n",
      "105/105 [==============================] - 639s 6s/step - loss: 0.2747 - acc: 0.9511 - recall_4: 0.9479 - auc_2: 0.9871 - val_loss: 0.0642 - val_acc: 1.0000 - val_recall_4: 1.0000 - val_auc_2: 1.0000\n",
      "Epoch 5/10\n",
      "105/105 [==============================] - 661s 6s/step - loss: 0.1723 - acc: 0.9651 - recall_4: 0.9621 - auc_2: 0.9948 - val_loss: 0.0793 - val_acc: 1.0000 - val_recall_4: 1.0000 - val_auc_2: 1.0000\n",
      "Epoch 6/10\n",
      "105/105 [==============================] - 612s 6s/step - loss: 0.1517 - acc: 0.9707 - recall_4: 0.9688 - auc_2: 0.9961 - val_loss: 0.0788 - val_acc: 1.0000 - val_recall_4: 1.0000 - val_auc_2: 1.0000\n",
      "Epoch 7/10\n",
      "105/105 [==============================] - 578s 6s/step - loss: 0.1006 - acc: 0.9764 - recall_4: 0.9734 - auc_2: 0.9981 - val_loss: 0.1270 - val_acc: 0.8750 - val_recall_4: 1.0000 - val_auc_2: 1.0000\n",
      "Epoch 8/10\n",
      "105/105 [==============================] - 542s 5s/step - loss: 0.1016 - acc: 0.9803 - recall_4: 0.9783 - auc_2: 0.9979 - val_loss: 0.0621 - val_acc: 0.9375 - val_recall_4: 1.0000 - val_auc_2: 1.0000\n",
      "Epoch 9/10\n",
      "105/105 [==============================] - 636s 6s/step - loss: 0.0606 - acc: 0.9893 - recall_4: 0.9881 - auc_2: 0.9991 - val_loss: 0.0110 - val_acc: 1.0000 - val_recall_4: 1.0000 - val_auc_2: 1.0000\n",
      "Epoch 10/10\n",
      "105/105 [==============================] - 696s 7s/step - loss: 0.0410 - acc: 0.9914 - recall_4: 0.9899 - auc_2: 0.9996 - val_loss: 0.1458 - val_acc: 0.9375 - val_recall_4: 1.0000 - val_auc_2: 1.0000\n"
     ]
    }
   ],
   "source": [
    "cnn1 = cnn.fit(X_train, y_train,\n",
    "               epochs=10,\n",
    "               batch_size=50,\n",
    "               validation_data = (X_val, y_val), \n",
    "               class_weight=weights,\n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-44e9fd0a382b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhist_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist_cnn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mval_loss_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist_cnn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mauc_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist_cnn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mval_auc_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist_cnn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "hist_cnn = cnn.history\n",
    "loss_values = hist_cnn['loss']\n",
    "val_loss_values = hist_cnn['val_loss']\n",
    "auc_values = hist_cnn['auc'] \n",
    "val_auc_values = hist_cnn['val_auc']\n",
    "acc_values = hist_cnn['acc'] \n",
    "val_acc_values = hist_cnn['val_acc']\n",
    "recall_values = hist_cnn['recall'] \n",
    "val_recall_values = hist_cnn['val_recall']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "\n",
    "plt.subplots(2,2, figsize=(15, 12))\n",
    "plt.subplot(121)\n",
    "plt.plot(epochs, loss_values, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'g', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(epochs, auc_values, 'r.', label='Training auc')\n",
    "plt.plot(epochs, val_auc_values, 'r', label='Validation auc')\n",
    "plt.title('Training and validation AUC')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('AUC')\n",
    "\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.plot(epochs, acc_values, 'r.', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc_values, 'r', label='Validation Accuracy')\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(epochs, recall_values, 'r.', label='Training Recall')\n",
    "plt.plot(epochs, val_recall_values, 'r', label='Validation Recall')\n",
    "plt.title('Training and validation Recall')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(fit_model, X, threshold):\n",
    "    return [1 if x >= threshold else 0 for x in fit_model.predict(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_false_positive(true, prediction):\n",
    "    return [1 if (x == 0 and y == 1) else 0 for x,y in zip(true,prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_positive(true, prediction):\n",
    "    return [1 if (x == 1 and y == 1) else 0 for x,y in zip(true,prediction)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_labels(cnn1, X_test, 0.5)\n",
    "fp = get_false_positive(y_test, predictions)\n",
    "tp = get_true_positive(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 16s 810ms/step - loss: 2.4843 - acc: 0.7212 - recall_4: 0.9949 - auc_2: 0.7391\n"
     ]
    }
   ],
   "source": [
    "validation1_1 = cnn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation1_3 = cnn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 91s 559ms/step - loss: 0.0810 - acc: 0.9689 - recall: 0.9646 - auc: 0.9965\n"
     ]
    }
   ],
   "source": [
    "validation1_ = cnn.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ../../src/models/2020-12-02tim-1.HDF5/assets\n"
     ]
    }
   ],
   "source": [
    "today = str(datetime.today()).split()[0]\n",
    "directory = \"../../src/models/\"\n",
    "model_id = \"tim-2\"\n",
    "file = directory+today+model_id+\".HDF5\"\n",
    "cnn.save(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 8s 418ms/step - loss: 0.8882 - acc: 0.7308 - recall_2: 1.0000 - auc_1: 0.9112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8882023692131042, 0.7307692170143127, 1.0, 0.9111714363098145]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1 = models.load_model(\"../../src/models/2020-12-02tim-1.HDF5/\")\n",
    "\n",
    "cnn1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 254, 254, 64)      640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 127, 127, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 125, 125, 32)      18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 123008)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                3936288   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,955,937\n",
      "Trainable params: 3,955,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 16s 796ms/step - loss: 1.7555 - acc: 0.7788 - recall_7: 0.9872 - auc_2: 0.8070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7555465698242188,\n",
       " 0.7788461446762085,\n",
       " 0.9871794581413269,\n",
       " 0.8070019483566284]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_46 (Conv2D)           (None, 254, 254, 64)      640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 127, 127, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 125, 125, 32)      18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 123008)            0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 32)                3936288   \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,955,937\n",
      "Trainable params: 3,955,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential()\n",
    "adam = Adam()\n",
    "recall = Recall()\n",
    "AUC = AUC()\n",
    "\n",
    "# Input layer conv\n",
    "cnn.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256,  1)))\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# First hidden layer conv\n",
    "cnn.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn.add(layers.Dropout(0.2))\n",
    "cnn.add(layers.Flatten())\n",
    "\n",
    "# Added first dense layer\n",
    "cnn.add(layers.Dense(32, activation='relu'))\n",
    "cnn.add(layers.Dropout(.2))\n",
    "\n",
    "# Add Second Layer\n",
    "cnn.add(layers.Dense(16, activation='relu'))\n",
    "cnn.add(layers.Dropout(.1))\n",
    "cnn.add(layers.Dense(1, activation='sigmoid'))\n",
    "cnn.compile(loss='binary_crossentropy',\n",
    "              optimizer= adam,\n",
    "              metrics=['acc', recall, AUC])\n",
    "\n",
    "cnn1 = cnn.fit(X_train, y_train,\n",
    "               epochs=7,\n",
    "               batch_size=50,\n",
    "               validation_data = (X_val, y_val), \n",
    "               class_weight=weights,\n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second model\n",
    "\n",
    "I added a second hidden layer and I added dropout = 0.1 to the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/105 [..............................] - ETA: 0s - loss: 1.4348 - acc: 0.5000 - recall_13: 0.5135 - auc_3: 0.4553"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-291-804564b09e45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m                \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                verbose=True)\n\u001b[0m",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn2 = models.Sequential()\n",
    "adam2 = Adam()\n",
    "recall = Recall()\n",
    "AUC = AUC()\n",
    "\n",
    "# Input Layer conv\n",
    "cnn2.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256,1)))\n",
    "cnn2.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn2.add(layers.Dropout(0.1))\n",
    "\n",
    "# First hidden Layer conv\n",
    "cnn2.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn2.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn2.add(layers.Dropout(0.5))\n",
    "\n",
    "# Second hidden Layer conv\n",
    "cnn2.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "cnn2.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn2.add(layers.Dropout(0.5))\n",
    "cnn2.add(layers.Flatten())\n",
    "\n",
    "# Added first Layer dense\n",
    "cnn2.add(layers.Dense(32, activation='relu'))\n",
    "cnn2.add(layers.Dropout(.5))\n",
    "\n",
    "# Add Second Layer dense\n",
    "cnn2.add(layers.Dense(16, activation='relu'))\n",
    "cnn2.add(layers.Dropout(.5))\n",
    "\n",
    "# Output Layer dense\n",
    "cnn2.add(layers.Dense(1, activation='sigmoid'))\n",
    "cnn2.compile(loss='binary_crossentropy',\n",
    "              optimizer= adam2,\n",
    "              metrics=['acc', recall, AUC])\n",
    "\n",
    "history2 = cnn2.fit(X_train, y_train,\n",
    "               epochs=5,\n",
    "               batch_size=50,\n",
    "               validation_data = (X_test, y_test), \n",
    "               class_weight=weights,\n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = str(datetime.today()).split()[0]\n",
    "directory = \"../../src/models/\"\n",
    "model_id = \"tim-2\"\n",
    "file = directory+today+model_number+\".HDF5\"\n",
    "cnn2.save(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation2_ = cnn2.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation2_2 = cnn2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation2_3 = cnn2.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3 = models.Sequential()\n",
    "adam3 = Adam()\n",
    "recall3 = Recall()\n",
    "AUC3 = AUC()\n",
    "# Input Layer conv\n",
    "cnn3.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256,1)))\n",
    "cnn3.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn3.add(layers.Dropout(0.1))\n",
    "\n",
    "# First hidden Layer conv\n",
    "cnn3.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn3.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn3.add(layers.Dropout(0.5))\n",
    "\n",
    "# Second hidden Layer conv\n",
    "cnn3.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "cnn3.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn3.add(layers.Dropout(0.5))\n",
    "cnn3.add(layers.Flatten())\n",
    "\n",
    "# Added first Layer dense\n",
    "cnn3.add(layers.Dense(32, activation='relu'))\n",
    "cnn3.add(layers.Dropout(.5))\n",
    "\n",
    "# Add Second Layer dense\n",
    "cnn3.add(layers.Dense(16, activation='relu'))\n",
    "cnn3.add(layers.Dropout(.5))\n",
    "\n",
    "# Output Layer dense\n",
    "cnn3.add(layers.Dense(1, activation='sigmoid'))\n",
    "cnn3.compile(loss='binary_crossentropy',\n",
    "              optimizer= adam2,\n",
    "              metrics=['acc', recall3, AUC3])\n",
    "\n",
    "history3 = cnn3.fit(X_train, y_train,\n",
    "               epochs=10,\n",
    "               batch_size=50,\n",
    "               validation_data = (X_val, y_val), \n",
    "               class_weight=weights,\n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation3_1 = cnn3.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation3_2 = cnn3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation3_3 = cnn3.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = str(datetime.today()).split()[0]\n",
    "directory = \"../../src/models/\"\n",
    "model_id = \"tim-3\"\n",
    "file = directory+today+model_number+model_id+\".HDF5\"\n",
    "cnn3.save(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
